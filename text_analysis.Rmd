---
title: "text_analysis"
output: html_document
date: "2024-02-12"
---

```{r}
library(tidyverse)
library(quanteda)
library(ggplot2)
library(quanteda.textplots)
library(quanteda.textstats)
library(stopwords)
library(forcats)
library(tidytext)
#library(ggwordcloud)
options(scipen=999)
Sys.setlocale("LC_ALL", 'tr_TR.UTF-8')
```

```{r message=FALSE, warning=FALSE}
theme_poppins <- function() {
  theme_minimal() +
    theme(
      text = element_text(family = "Poppins", color = "gray25"),
      plot.title = element_text(face = "bold",size = 12),
      plot.title.position = "plot",
      plot.subtitle = element_text(size = 11),
      axis.text.x= element_text(size=10),
      axis.text.y = element_text(size=10),
      plot.caption = element_text(size = 10, color = "gray30"),
      plot.background = element_rect(fill = "#ffffff"),
      legend.position = "none",
      strip.background = element_rect(colour = "#d9d9d9", fill = "#d9d9d9"),
      strip.text.x = element_text(size = 10, colour = "gray25", face = "bold"))
}
```
***


```{r}
ht <- readRDS("~/Rstats/iklimdeg/tweets_sentiment.rds") %>% filter(!user_username %in% c("gazeteduvar","ahaber","ntv"))

glimpse(ht)
```


```{r}
ht %>% group_by(gpt4_sentiment) %>% summarise(mean(like_count), mean(retweet_count)) 
```


```{r}
ht %>% count(user_username, sort = T) %>%  mutate(perc = n/sum(n))
ht %>% count(ideoloji, sort = T) %>% mutate(perc = n/sum(n))
```

```{r}
ht %>% ggplot(aes(tarih))+geom_histogram(bins = 100)+theme_poppins()
```


```{r}
ht %>% ggplot(aes(tarih, fill = ideoloji))+geom_histogram(bins = 100, alpha = 0.7)+theme_poppins()+facet_wrap(~user_username) + scale_fill_manual(values = c("darkorange","darkblue","darkgreen"))


ht %>% ggplot(aes(tarih, fill = ideoloji))+geom_histogram(bins = 100,alpha = 0.7)+theme_poppins()+facet_wrap(~ideoloji)+ scale_fill_manual(values = c("darkorange","darkblue","darkgreen"))
```


***

*TEXT ANALYSIS*

```{r}
haber_corpus <-  corpus(ht)
summary(haber_corpus) %>% head()
```

```{r}
ntoken(haber_corpus) %>% sum()
nsentence((haber_corpus)) %>% sum()
```

```{r}
s
```


```{r}

custom_stopwords <- c("ortaya","Ã§Ä±ktÄ±","iÃ§inde","yÄ±l","karÅŸÄ±ya","dikkat","Ã§ekmek","son","yÄ±lda","yol","aÃ§tÄ±ÄŸÄ±","ilan","edildi","gÃ¼rbÃ¼z","yazdÄ±","karÅŸÄ±","haberturk","rt","a","ye","in","deÄŸiÅŸik*","iklim","bir","ii","iÌ‡klim")



haber_toks <- tokens(haber_corpus, 
                  remove_punct = T, remove_numbers = T, remove_url = T, 
                  remove_symbols = T) %>% 
  tokens_select(pattern = stopwords(language = "tr",source = "stopwords-iso"), selection = "remove") %>% 
   tokens_select(pattern = stopwords(language = "tr",source = "nltk"), selection = "remove") %>% 
  tokens_replace(pattern = "['â€™].*", valuetype = "regex", replacement = "") %>% 
  tokens_select(pattern = custom_stopwords, selection = "remove") %>% 
  tokens_remove(pattern = "@*") %>% 
  tokens_remove(pattern = "[:emoji:]", valuetype = "regex") %>% 
  tokens_remove(pattern = "#*") 

haber_toks_stem <- tokens(haber_corpus, 
                  remove_punct = T, remove_numbers = T, remove_url = T, 
                  remove_symbols = T) %>% 
  tokens_select(pattern = stopwords(language = "tr",source = "stopwords-iso"), selection = "remove") %>% 
   tokens_select(pattern = stopwords(language = "tr",source = "nltk"), selection = "remove") %>% 
  tokens_replace(pattern = "['â€™].*", valuetype = "regex", replacement = "") %>% 
  tokens_select(pattern = custom_stopwords, selection = "remove") %>% 
  tokens_remove(pattern = "@*") %>% 
  tokens_remove(pattern = "#*") %>%
  tokens_wordstem(language = "tr")
```


```{r}
unigrams_dfm <- dfm(haber_toks) 
top_unigrams <- textstat_frequency(unigrams_dfm) %>% filter(nchar(feature)>0)
top_unigrams %>% head()
```

`

**bigram**

```{r}
bigrams_dfm <- haber_toks %>% 
  tokens_remove(pattern = c("ortaya","Ã§Ä±ktÄ±","iÃ§inde","yÄ±l","karÅŸÄ±ya","dikkat","Ã§ekmek","son","yÄ±lda","yol","aÃ§tÄ±ÄŸÄ±","ilan","edildi")) %>% 
  tokens_replace(pattern = "Ä±sÄ±nma*", replacement = "Ä±sÄ±nma") %>% 
  tokens_replace(pattern = "alarmÄ±*", replacement = "uyarÄ±sÄ±") %>% 
  tokens_ngrams(n = 2) %>% dfm() %>% 
  dfm_replace(pattern = "bm_genel", replacement = "birleÅŸmiÅŸ_milletler") %>% 
  dfm_replace(pattern = "kÃ¼resel_Ä±sÄ±nma+", replacement = "kÃ¼resel_Ä±sÄ±nma") %>% dfm_remove(pattern ="	
ğŸ–Šï¸_Ã¶zer" )

```

```{r}
tidy_gen_bigrams <- textstat_frequency(bigrams_dfm) %>% filter(!feature %in% c("kuraklÄ±k_su","ÅŸiddetli_kuraklÄ±k",
"Ã¶nlem_alÄ±nmazsa","kuraklÄ±k_aÃ§Ä±klamasÄ±","kuraklÄ±kla_mÃ¼cadele","olaÄŸanÃ¼stÃ¼_kuraklÄ±k","dÃ¼nyanÄ±n_bÃ¼yÃ¼k","bÃ¼yÃ¼k_tehlike","devam_ederse","bÃ¼yÃ¼k_tehdit","yaÅŸanan_kuraklÄ±k","kuraklÄ±k_vurdu","serdar_m","ayÅŸe_Ã¶zek","Ã¼lke_olacak","gÃ¶lÃ¼_kuraklÄ±k","geÃ§en_gÃ¼n", "âœ’ï¸_Ã¶zer"))

tidy_gen_bigrams %>%  slice_max(frequency, n= 20) %>% 
  ggplot(aes(fct_reorder(feature, frequency),frequency))+
  geom_col(fill ="#2b61a1")+
  coord_flip()+
  labs(x="",y="")+theme_poppins()+labs()+theme_poppins()

#ggsave("top20_gen_bigram2.png",width = 7, height = 6, dpi = 600)
```
```{r}
fr <- tidy_gen_bigrams %>%  slice_max(frequency, n= 23) %>% pull(frequency)
fr
```




```{r}
tibble(feature = c("global warming","professor","drought warning","president erdogan",
                   "greenhouse gas","united nations","scientists","water level","drought issue",
                   "environment urbanization","associate profesor","global crisis","greta thunberg",
                   "water shortage","chamber of engineers","emine erdogan","thirst drought","warm weather",
                   "experiencing drought","dam occupancy","doganay tolunay","chp member","us president"
                   ),
       frequency = fr) %>% ggplot(aes(fct_reorder(feature, frequency),frequency))+
  geom_col(fill ="#2b61a1")+
  coord_flip()+
  labs(x="",y="")+theme_poppins()+labs()+theme_poppins()

ggsave("top20_gen_bigram_en.png",width = 7, height = 6, dpi = 600)
```



```{r}
textplot_wordcloud(bigrams_dfm, max_words = 100, min_size = 1)
```



```{r}
tidy_gen_bigrams2 <- textstat_frequency(bigrams_dfm, groups = ideoloji) %>% filter(!feature %in% c("kuraklÄ±k_su","ÅŸiddetli_kuraklÄ±k",
"Ã¶nlem_alÄ±nmazsa","kuraklÄ±k_aÃ§Ä±klamasÄ±","kuraklÄ±kla_mÃ¼cadele","olaÄŸanÃ¼stÃ¼_kuraklÄ±k","dÃ¼nyanÄ±n_bÃ¼yÃ¼k","bÃ¼yÃ¼k_tehlike","devam_ederse","bÃ¼yÃ¼k_tehdit","yaÅŸanan_kuraklÄ±k","kuraklÄ±k_vurdu","serdar_m","ayÅŸe_Ã¶zek","tuÄŸÃ§e_madayanti","m_deÄŸirmencioÄŸlu","geÃ§en_artÄ±yor","Ã¶zek_karasu","Ã¼lke_olacak","sÄ±kÄ±ntÄ±sÄ±_geÃ§en","kaleme_aldÄ±","Ã¶zer_akdemir","dr_doÄŸanay","artÄ±yor_uzmanlara","alÄ±nmazsa_tÃ¼rkiye","âœ’ï¸_Ã¶zer"))

tidy_gen_bigrams2$group <- factor(tidy_gen_bigrams2$group, levels = c("conservative","center","progressive"))


head(tidy_gen_bigrams2, 50)

tidy_gen_bigrams2 %>%  group_by(group) %>% 
  slice_max(frequency, n = 15, with_ties = F) %>% 
  mutate(feature = reorder_within(feature,frequency,group)) %>%
  ggplot(aes(frequency, feature, fill = group)) +
  geom_col(show.legend = FALSE) +
  labs(x = "frequency", y = NULL) +
  facet_wrap(~group, ncol = 3, scales = "free")+
  theme_poppins()+ scale_y_reordered()+scale_fill_manual(values = c("#FF6868","#FBA834","#2D9596"))

#ggsave("top20_gen_bigram2.png",width = 9, height = 5, dpi = 600)
```
```{r}
group <- tidy_gen_bigrams2 %>%  group_by(group) %>% 
  slice_max(frequency, n = 15, with_ties = F) %>% pull(group)

freq <- tidy_gen_bigrams2 %>%  group_by(group) %>% 
  slice_max(frequency, n = 15, with_ties = F) %>% pull(frequency)

```



```{r}
#translation Turkish words to English for the publication
tibble(feature = c("global warming","president erdogan","professor","united nations","drought warning",
                   "emine erdogan","murat kurum","water level","environment urbanization","zero waste",
                   "struggle","urban minister","greenhouse gas","worldwide","european union",
                   
                   "global warming","professor","drought warning","scientists","water level","drought danger",
                   "president erdogan","water shortage","greenhouse gas","expert precaution",
                   "drought risk","floods","global crisis","experiencing drought","impact farmers",
                   
                   "global warming","professor","drought warning","greenhouse gas","united nations","thirst drought",
                   "daganay tolunay", "chamber of engineers","global resistance","experiencing drought",
                   "greta thunberg","associate professor","fossil fuel","chp member","action plan"),
      frequency = freq,
      group = group) %>% group_by(group) %>% 
  slice_max(frequency, n = 15, with_ties = F) %>% 
  mutate(feature = reorder_within(feature,frequency,group)) %>%
  ggplot(aes(frequency, feature, fill = group)) +
  geom_col(show.legend = FALSE) +
  labs(x = "frequency", y = NULL) +
  facet_wrap(~group, ncol = 3, scales = "free")+
  theme_poppins()+ scale_y_reordered()+scale_fill_manual(values = c("#FF6868","#FBA834","#2D9596"))

ggsave("top20_gen_bigram2_en.png",width = 9, height = 5, dpi = 600)
```


**Co-locations**

```{r}
toks_news <- tokens(haber_corpus, remove_punct = TRUE, remove_url = TRUE,
                    remove_symbols = TRUE) %>% tokens_replace(pattern = "ErdoÄŸan'dan", replacement = "ErdoÄŸan")

tstat_col_caps <- tokens_select(toks_news, pattern = "^[A-Z]", 
                                valuetype = "regex", 
                                case_insensitive = FALSE, 
                                padding = TRUE) %>% 
  textstat_collocations(min_count = 3,size =2,tolower = FALSE)


tstat_col_caps


tstat_col_caps %>% 
  slice_max(z, n= 20) %>% 
  ggplot(aes(fct_reorder(collocation, z),z))+
  geom_col(fill ="#2b61a1")+
  coord_flip()+
  labs(x="",y="")+theme_poppins()+labs()+theme_poppins()

ggsave("top20_colocations.png",width = 7, height = 6, dpi = 600)
```



*BY NEWS ORGS*

```{r}
library(tidylo)
```


```{r}

custom_stopwords <- c("https","tuÄŸÃ§e","Ã¶zek","Ã¶zer","m","ortaya","Ã§Ä±ktÄ±","iÃ§inde","yÄ±l","karÅŸÄ±ya","dikkat","Ã§ekmek","son","yÄ±lda","yol","aÃ§tÄ±ÄŸÄ±","ilan","edildi","gÃ¼rbÃ¼z","yazdÄ±","karÅŸÄ±","haberturk","rt","a","ye","in","deÄŸiÅŸik*","iklim","bir","ii","iÌ‡klim")

custom_stopwords2 <-  c("deÄŸirmencioÄŸlu","dÃ¼nyanÄ±n","devam","ederse","serdar","m","ayÅŸe","Ã¶zek","tuÄŸÃ§e",
                       "madayanti","m","deÄŸirmencioÄŸlu","geÃ§en","artÄ±yor","Ã¶zek","karasu","Ã¼lke","olacak",
                       "sÄ±kÄ±ntÄ±sÄ±","geÃ§en","kaleme","aldÄ±","Ã¶zer","akdemir","artÄ±yor","uzmanlara",
                       "alÄ±nmazsa","tÃ¼rkiye","Ä±","yeni","ÅŸafak","habertÃ¼rk","yazarÄ±","ihsan","Ã§aralan","yÃ¼cel","Ã¶zdemir","Ã¶zgÃ¼r","demet","sargÄ±n","hediye","levent","sÄ±rada","yer","harekete","geÃ§ti","Ã¶ne","sÃ¼ren")

haber_toks <- tokens(haber_corpus, 
                  remove_punct = T, remove_numbers = T, remove_url = T, 
                  remove_symbols = T) %>% 
  tokens_select(pattern = stopwords(language = "tr",source = "stopwords-iso"), selection = "remove") %>% 
   tokens_select(pattern = stopwords(language = "tr",source = "nltk"), selection = "remove") %>% 
  tokens_replace(pattern = "['â€™].*", valuetype = "regex", replacement = "") %>% 
  tokens_select(pattern = custom_stopwords, selection = "remove") %>% 
  tokens_select(pattern = custom_stopwords2, selection = "remove") %>%
  tokens_remove(pattern = "@*") %>% 
  tokens_remove(pattern = "#*") 


```

```{r}
unigrams_dfm <- dfm(haber_toks)
bigrams_dfm <- haber_toks %>% tokens_ngrams(n=2) %>% dfm()
```




```{r}

log_odds_ideo <- unigrams_ideo %>%  bind_log_odds(group, feature, frequency) 

log_odds_ideo$group <- factor(log_odds_ideo$group, levels = c("conservative","center","progressive"))

head(log_odds_ideo,30)
```



```{r}
log_odds_ideo %>% filter(group!="na") %>% 
  group_by(group) %>% 
  slice_max(log_odds_weighted, n = 20, with_ties = F) %>% 
  ungroup() %>%
  mutate(word = reorder_within(feature,log_odds_weighted, group)) %>%
  ggplot(aes(log_odds_weighted, word, fill = group)) +
  geom_col(show.legend = FALSE) +
  labs(x = "log_odds_weighted", y = NULL) +
  facet_wrap(~group, ncol = 3, scales = "free")+theme_poppins()+
    scale_y_reordered()+
  scale_fill_manual(values = c("#FF6868","#FBA834","#2D9596"))
```


```{r}
bigrams_ideo <- textstat_frequency(bigrams_dfm, groups = ideoloji) %>% filter(nchar(feature)>0)
log_odds_ideo2 <- bigrams_ideo %>%  bind_log_odds(group, feature, frequency)

log_odds_ideo2$group <- factor(log_odds_ideo2$group, levels = c("conservative","center","progressive"))

head(log_odds_ideo2,30)
```




```{r}
log_odds_ideo2 %>% filter(group!="na") %>% 
  group_by(group) %>% 
  slice_max(log_odds_weighted, n = 15, with_ties = F) %>% 
  ungroup() %>%
  mutate(word = reorder_within(feature,log_odds_weighted, group)) %>%
  ggplot(aes(log_odds_weighted, word, fill = group)) +
  geom_col(show.legend = FALSE) +
  labs(x = "log_odds_weighted", y = NULL) +
  facet_wrap(~group, ncol = 3, scales = "free")+theme_poppins()+
    scale_y_reordered()+scale_fill_manual(values = c("#FF6868","#FBA834","#2D9596"))


```

*KEYNESS BY IDEOLOGY*


```{r}

new_bigrams_dfm <- bigrams_dfm %>% dfm_subset(docvars(bigrams_dfm)$ideoloji %in% c("conservative","progressive")) %>% dfm_select(pattern = "[A-Za-z]*", valuetype = "regex",selection = "keep")

tstat_key <- textstat_keyness(new_bigrams_dfm, 
                              target = (docvars(new_bigrams_dfm)$ideoloji == "conservative")) %>% filter(feature != "cumhurbaÅŸkanÄ±_erdoÄŸan")

textplot_keyness(tstat_key, n = 20, font = "Poppins",color = c("#FF6868", "#2D9596"))+theme(legend.position = "none")+xlim(-10,21)

#ggsave("bigram_keyness.png", width = 10, height = 9, dpi = 600)
#ggsave("bigram_keyness.svg", width = 10, height = 9, dpi = 600)
```

```{r}
feature1= c("president erdogan","emine erdogan","zero waste","struggle","urban minister","environmental education",
           "water level","environment urbanization","experiencing drought","murat kurum","waste verdict",
           "minister pekdemirli","energy conversion","melting glaciers","development plan","general assembly","red alert","global scale","minister of forestry","sustainable development")


feature2= c("doganay tolunay","water shortage","global resistance","gave hope","Ã¶zer akdemir","global warming","dr doganay","drought warning","professor","chamber of engineers","action plan","greenhouse gas","urgent measure","climate alarming","chp member","dr mikdat", "dr murat","ecological destruction","enviromental engineers", "extreme drought")
```

```{r}
tstat_key2 <- bind_rows(tstat_key %>% slice_max(chi2, n=20) %>% head(20) %>% mutate(feature = feature1),

tstat_key %>% slice_min(chi2, n=20) %>% head(20) %>% mutate(feature = feature2))

textplot_keyness(tstat_key2, n = 20, font = "Poppins",color = c("#FF6868", "#2D9596"))+theme(legend.position = "none")+xlim(-10,21)

ggsave("bigram_keyness_en.png", width = 10, height = 9, dpi = 600)
```


